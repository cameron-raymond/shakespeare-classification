{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare Classification\n",
    "\n",
    "Three Goals:\n",
    "1. Visualize and explore relationships between characters in all of Shakespeare's plays.\n",
    "2. Determine a way to compare these networks of relationships\n",
    "3. Build a model that uses this comparison metric to distinguish between comedies and tragedies *without looking at any dialogue.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "We're downloading the dialouge from all of Shakespeare's plays via Kaggle. The below cell contains what you'd run in your terminal, but to do so you need to have a Kaggle Account/API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "# subprocess.run(\"kaggle datasets download -d kingburrito666/shakespeare-plays && unzip shakespeare-plays.zip\",shell=True)\n",
    "plays_df = pd.read_csv(\"Shakespeare_data.csv\")\n",
    "print(\"{} rows\".format(plays_df.shape[0]))\n",
    "plays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop stage directions (where there isn't an act/scene/line)\n",
    "plays_df = plays_df[pd.notna(plays_df['ActSceneLine'])]\n",
    "plays_df[['Act','Scene','Line']] = plays_df['ActSceneLine'].str.split('.',expand = True).astype(float)\n",
    "plays_df = plays_df.drop('ActSceneLine',axis=1)\n",
    "# Standardize play casing\n",
    "plays_df['Play'] = plays_df['Play'].apply(lambda x: x.title())\n",
    "plays_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove plays defined as \"histories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = [\"King John\", \"Henry Iv\", \"Henry Vi Part 1\", \"Henry V\",\n",
    "            \"Henry Vi Part 2\", \"Henry Vi Part 3\", \"Henry Viii\", \"Richard Ii\", \n",
    "             \"Richard Iii\"]\n",
    "\n",
    "comedies = [\"A Midsummer Nights Dream\", \"A Comedy Of Errors\", \"Taming Of The Shrew\",\n",
    "            \"Two Gentlemen Of Verona\", \"Loves Labours Lost\", \"The Tempest\", \n",
    "            \"A Winters Tale\", \"Cymbeline\", \"Pericles\",\"Alls Well That Ends Well\",\n",
    "            \"Measure For Measure\", \"Troilus And Cressida\", \"Twelfth Night\", \n",
    "            \"As You Like It\", \"Much Ado About Nothing\", \"Merchant Of Venice\",\n",
    "            \"Merry Wives Of Windsor\"]\n",
    "\n",
    "tragedies = [\"Macbeth\",\"Titus Andronicus\", \"Romeo And Juliet\", \"King Lear\",\n",
    "            \"Hamlet\",\"Othello\", \"Julius Caesar\", \"Antony And Cleopatra\", \n",
    "            \"Coriolanus\", \"Timon Of Athens\"]\n",
    "\n",
    "plays_df = plays_df[~plays_df[\"Play\"].isin(histories)]\n",
    "print(\"{} rows and {} columns\".format(*plays_df.shape))\n",
    "plays_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the plays we have to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_list = plays_df[\"Play\"].unique()\n",
    "play_list\n",
    "print(len(play_list))\n",
    "print(play_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "play_name = \"Romeo And Juliet\"\n",
    "single_play = plays_df[(plays_df['Play'] == play_name)]\n",
    "single_play.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build play network\n",
    "\n",
    "### Drop characters who speak < 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group the play dataframe by each character to get how often they speak\n",
    "top_characters = single_play.groupby(['Player']).size().reset_index()\n",
    "top_characters.rename(columns = {0: 'Count'}, inplace = True)\n",
    "\n",
    "top_characters = top_characters[top_characters[\"Count\"] > 5]\n",
    "top_characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Graph and add all the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "character_graph = nx.Graph()\n",
    "character_graph.add_nodes_from(top_characters[\"Player\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go scene by scene and add links between all the characters who spoke in that scene\n",
    "\n",
    "We're updating the weights as we go scene by scene so that  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the play by the Act/Scene and get how much each character spoke in that scene \n",
    "character_counts = single_play.groupby(['Act','Scene','Player']).size().reset_index()\n",
    "character_counts = character_counts[character_counts[\"Player\"].isin(top_characters[\"Player\"])]\n",
    "character_counts.rename(columns = {0: 'Count'}, inplace = True)\n",
    "character_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Go scene by scene\n",
    "for (act,scene), counts in character_counts.groupby(['Act','Scene']):\n",
    "    # Get all the characters that are in that scene\n",
    "    characters = counts[\"Player\"].tolist()\n",
    "    # If a scene contains characters [A,B,C] we want are graph to \n",
    "    # contain the edges [(A,B),(A,C),(B,C)]\n",
    "    pairs = list(combinations(characters,2))\n",
    "    for (a_char, b_char) in pairs:\n",
    "        if character_graph.has_edge(a_char, b_char):\n",
    "            # we added this one before, just increase the weight by one\n",
    "            character_graph[a_char][b_char]['weight'] += 1\n",
    "        else:\n",
    "            # new edge. add with weight=1\n",
    "            character_graph.add_edge(a_char, b_char, weight =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing NX graph object\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "plt.figure(figsize = (8,6), dpi = 180)\n",
    "plt.title(\"{} ({})\".format(play_name,\"Comedy\" if play_name in comedies else \"Tragedy\"))\n",
    "\n",
    "pos = graphviz_layout(character_graph, prog=\"neato\")\n",
    "# Divide all the weights by 30 so that the edges aren't super thick\n",
    "weights = np.array([character_graph[u][v]['weight'] for u,v in character_graph.edges()])\n",
    "kwargs = {\n",
    "    \"with_labels\": True,\n",
    "    \"node_size\": 400,\n",
    "    \"node_color\": 'grey',\n",
    "    \"font_size\": 8,\n",
    "    \"font_weight\": 'semibold',\n",
    "    \"width\": weights,\n",
    "    \"edge_color\": weights, \n",
    "    \"edge_cmap\": plt.cm.Blues,\n",
    "    \"pos\": pos\n",
    "}\n",
    "nx.draw_networkx(character_graph, **kwargs)\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "# plt.savefig(\"./visualizations/{}.png\".format(play_name))\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the character graph to a file for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(character_graph, \"./graphs/{}.gpickle\".format(play_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Repeat with all other plays...*\n",
    "\n",
    "![SegmentLocal](networks.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetLSD: Calculate Heat Traces\n",
    "\n",
    "The idea behind classifying these plays is that at some global and local levels, tragedies and comedies have different patterns of communication. This can be captured by simulating how the dialogue \"flows\" through the network. This uses the heat kernel and is directly analogous to modelling how heat diffuses throughout a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into training and testing data\n",
    "data = np.array(comedies+tragedies)\n",
    "labels = np.concatenate([np.full(len(comedies), \"c\"),np.full(len(tragedies), \"t\")])\n",
    "# Label map\n",
    "lm = {\n",
    "    \"c\": (\"Comedy\",\"blue\"),\n",
    "    \"t\": (\"Tragedy\",\"red\")\n",
    "}\n",
    "priors, test_data, prior_labels, test_labels = train_test_split(data, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate point of truth heat signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import netlsd\n",
    "kwargs = {\n",
    "    \"timescales\": np.logspace(-2, 2, 250),\n",
    "    \"normalization\": \"empty\"\n",
    "}\n",
    "\n",
    "get_sig = lambda title: netlsd.heat(nx.read_gpickle(\"./graphs/{}.gpickle\".format(title)),**kwargs)\n",
    "\n",
    "prior_heat_sigs =[get_sig(title) for title in priors]\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_title(\"Observed Heat Signatures\")\n",
    "ax.set_ylabel('h(t)', fontsize = 15)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_xscale('log')\n",
    "ax.grid()\n",
    "\n",
    "for sig,name,ptype in zip(prior_heat_sigs,priors,prior_labels):\n",
    "    ax.plot(kwargs[\"timescales\"],sig, color=lm[ptype][1])\n",
    "\n",
    "# Add legend\n",
    "for key, item in lm.items():\n",
    "    ax.plot([], [], label=item[0], color=item[1])\n",
    "ax.legend(loc=\"best\")\n",
    "plt.show()\n",
    "# plt.savefig(\"./visualizations/training_heat_sigs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Class of Test Data via KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netlsd import compare as l2_distance\n",
    "\n",
    "def knn_predict(title, training_heat_sigs, training_titles, labels_train,k=5):\n",
    "    # Read in the play's network and calculate it's heat trace signature using the same arguments as the training data\n",
    "    graph_sig = get_sig(title)\n",
    "    # Calcualte the distance between that graph and the training data's heat traces\n",
    "    distances = [l2_distance(graph_sig,train_sig) for train_sig in training_heat_sigs]\n",
    "    # I found that the most concise way to sort all three training inputs by distance was to \n",
    "    # put them in a dataframe first. If you're concerned about memory, other options are\n",
    "    # preferable\n",
    "    total = pd.DataFrame({\"Play Title\": training_titles, \"Play Type\": labels_train, \"Distance From Input\": distances})\n",
    "    total = total.sort_values(\"Distance From Input\")\n",
    "    print(title)\n",
    "    print(total.head(k))\n",
    "    return total[\"Play Type\"].head(k).mode()[0]\n",
    "\n",
    "\n",
    "pred = [knn_predict(play,prior_heat_sigs,priors,prior_labels,k=5) for play in test_data]\n",
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "classes = [\"Comedy\", \"Tragedy\"]\n",
    "cm = confusion_matrix(pred,test_labels)\n",
    "title = 'Shakespear Classification Confusion Matrix'\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "# We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "        # ... and label them with the respective list entries\n",
    "        xticklabels=classes, yticklabels=classes,\n",
    "        title=title,\n",
    "        ylabel='Predicted label',\n",
    "        xlabel='True label')\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "            rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "thresh = cm.max() / 2.\n",
    "fmt = 'd'\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"./visualizations/confusion_mat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is just a binary classification, calculating some metrics isn't too difficult\n",
    "# For simplicity we'll consider comedies to be the positive class and tragedies the negative\n",
    "# True positive => predicted a comedy and is a comedy\n",
    "true_positives = cm[0][0]\n",
    "# False positive => predicted a comedy and is a tragedy\n",
    "false_positives = cm[0][1]\n",
    "# False negative => predicted a tragedy and is a comedy\n",
    "false_negatives = cm[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/(true_positives+false_positives)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = true_positives/(true_positives+false_negatives)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = 2*((precision*recall)/(precision+recall))\n",
    "f_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
